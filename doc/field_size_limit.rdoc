====== Option +field_size_limit+

This is a maximum size CSV will read ahead looking for the closing quote for a field. (In truth, it reads to the first line ending beyond this size.) If a quote cannot be found within the limit CSV will raise a MalformedCSVError, assuming the data is faulty. You can use this limit to prevent what are effectively DoS attacks on the parser. However, this limit can cause a legitimate parse to fail and thus is set to nil, or off, by default.

The default is +nil+:
  CSV.new('').field_size_limit # => nil

  data = <<~DATA
    "a","b"
    "
    2345
    ",""
  DATA
  data # => "\"a\",\"b\"\n\"\n2345\n\",\"\"\n"
  # Raises CSV::MalformedCSVError (Field size exceeded in line 2.)
  CSV.parse(data, field_size_limit: 5)

For these examples:
  data = <<~DATA
    "a","b"
    "
    2345
    ",""
  DATA
  data # => "\"a\",\"b\"\n\"\n2345\n\",\"\"\n"
xxx
Using the default:
  csv = CSV.parse(data)
  csv # => [["a", "b"], ["\n2345\n", ""]]

Using the default:
  csv = CSV.parse(data)
  csv # => [["a", "b"], ["\n2345\n", ""]]

Using <tt>50</tt>:
  field_size_limit = 50
  csv = CSV.parse(data, field_size_limit: field_size_limit)
  csv # => [["a", "b"], ["\n2345\n", ""]]

Raises an exception if a field is too long:
  big_data = "123456789\n" * 1024
  # Raises CSV::MalformedCSVError (Field size exceeded in line 1.)
  CSV.parse('valid,fields,"' + big_data + '"', field_size_limit: 2048)